{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeb5cd3",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Travel.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038e8a8",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e34381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('ProdTaken', axis=1)\n",
    "y = data['ProdTaken']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f36c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.concat([X_train, pd.DataFrame(y_train)], axis=1)\n",
    "test =  pd.concat([X_test, pd.DataFrame(y_test)], axis=1)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a73924",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef594d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class CustomeridDropper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(['CustomerID'], axis=1)\n",
    "\n",
    "class DuplicatedDropper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.drop_duplicates(keep='first')\n",
    "        return X\n",
    "\n",
    "class MissingImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        for i in (X.select_dtypes(include = 'number').columns):\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X[i] = imputer.fit_transform(X[[i]])\n",
    "    \n",
    "        for i in (X.select_dtypes(include = ['object','category']).columns):\n",
    "            imputer = SimpleImputer(strategy='most_frequent')\n",
    "            X[i] = imputer.fit_transform(X[[i]])\n",
    "    \n",
    "        return X\n",
    "\n",
    "class ExtractAgeStructure(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['AgeStructure'] = pd.cut(X['Age'], [15,24,54,64], labels=['Early Working Age','Prime Working Age', 'Mature Working Age'])\n",
    "        return X\n",
    "\n",
    "class DeleteOutliers(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):        \n",
    "        X.loc[X['DurationOfPitch'] > 36.0, 'DurationOfPitch'] = 36.0\n",
    "        X.loc[X['NumberOfPersonVisiting'] > 5, 'NumberOfPersonVisiting'] = 5\n",
    "        X.loc[X['NumberOfFollowups'] > 6, 'NumberOfFollowups'] = 6\n",
    "        X.loc[X['NumberOfTrips'] > 22.0 , 'NumberOfTrips'] = 22.0\n",
    "        X.loc[X['MonthlyIncome'] > 38677.0, 'MonthlyIncome'] = 38677.0\n",
    "        return X\n",
    "\n",
    "class NumericTransformation(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        nums = ['Age', 'DurationOfPitch', 'NumberOfPersonVisiting', 'NumberOfFollowups','NumberOfTrips', 'NumberOfChildrenVisiting', 'MonthlyIncome']\n",
    "        for i in nums:\n",
    "            scaler = StandardScaler()\n",
    "            X[i]= scaler.fit_transform(X[i].values.reshape(len(X), 1))\n",
    "        \n",
    "        return X\n",
    "\n",
    "class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        typeofcontact_dict = {'Self Enquiry' : 0, 'Company Invited' : 1}\n",
    "        X['TypeofContact'] = [typeofcontact_dict[i] for i in X['TypeofContact']]\n",
    "\n",
    "        X.loc[X['Gender'] == 'Fe Male', 'Gender'] = 'Female'\n",
    "        gender_dict = {'Male' : 0, 'Female' : 1}\n",
    "        X['Gender'] = [gender_dict[i] for i in X['Gender']]\n",
    "\n",
    "        X.loc[X['MaritalStatus'] == 'Unmarried', 'MaritalStatus'] = 'Single'\n",
    "\n",
    "        encoder = OneHotEncoder()\n",
    "        categorical_cols = ['Occupation', 'ProductPitched', 'MaritalStatus','Designation','AgeStructure']\n",
    "        for i in categorical_cols:\n",
    "            matrix = encoder.fit_transform(X[[i]]).toarray()\n",
    "            column_names = X[i].unique().tolist()\n",
    "            for j in range(len(matrix.T)):\n",
    "                X[column_names[j]] = matrix.T[j]\n",
    "            X.drop([i], axis=1, inplace=True)\n",
    "        \n",
    "        return X\n",
    "\n",
    "class BalancingClass(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        y = X['ProdTaken'].values\n",
    "        column_names = X.drop(['ProdTaken'], axis=1).columns.tolist()\n",
    "        X = X.drop(['ProdTaken'], axis=1).values\n",
    "\n",
    "        smote = SMOTE(sampling_strategy=1,random_state = 42)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "\n",
    "        X = pd.DataFrame(X, columns=column_names)\n",
    "        y = pd.DataFrame(y, columns=['ProdTaken'])\n",
    "\n",
    "        X = pd.concat([y, X], axis=1)\n",
    "        \n",
    "        return X\n",
    "\n",
    "class ColumnsDropper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        significant_features = ['ProdTaken','Passport', 'Deluxe', 'Executive', 'Divorced', 'Basic', 'AVP', 'Age', 'Prime Working Age',\n",
    "                      'MonthlyIncome', 'NumberOfFollowups', 'Single', 'Mature Working Age', 'King', 'Manager',\n",
    "                      'PreferredPropertyStar', 'Married', 'CityTier', 'Super Deluxe', 'VP', 'DurationOfPitch',\n",
    "                      'Salaried', 'PitchSatisfactionScore', 'Large Business', 'Gender', 'Small Business', 'TypeofContact',\n",
    "                      'NumberOfTrips']\n",
    "        X.drop(columns=([col for col in X.columns.tolist() if col not in significant_features]), axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "with open('preprocessing_pipe.pkl', 'rb') as f:\n",
    "    preprocessing_pipe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4941e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessing_pipe.fit_transform(train)\n",
    "test = preprocessing_pipe.transform(test)\n",
    "\n",
    "test = test[train.columns.tolist()]\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5ccfe",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.ProdTaken\n",
    "X_train = train.drop(['ProdTaken'], axis= 1)\n",
    "\n",
    "y_test = test.ProdTaken\n",
    "X_test = test.drop(['ProdTaken'], axis= 1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def eval_classification(model, pred, xtrain, ytrain, xtest, ytest):\n",
    "    print(\"Accuracy (Train Set): %.2f\" % model.score(xtrain, ytrain))\n",
    "    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(ytest, pred))\n",
    "    print(\"\\nPrecision (Test Set): %.2f\" % precision_score(ytest, pred))\n",
    "    print(\"Recall (Test Set): %.2f\" % recall_score(ytest, pred))\n",
    "    print(\"F1-Score (Test Set): %.2f\" % f1_score(ytest, pred))\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(ytest, pred, pos_label=1)\n",
    "    print(\"AUC: %.2f\" % auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73151369",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57339fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(max_features=5, n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa5e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "eval_classification(rf, y_pred, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641339af",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "max_features_range = np.arange(1,11,1)\n",
    "n_estimators_range = np.arange(10,210,10)\n",
    "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292906d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "eval_classification(model, y_pred, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b151e",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgb = XGBClassifier(objective='binary:logistic', seed=42)\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_xgb.predict(X_test)\n",
    "eval_classification(model, y_pred, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208c7ee",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201eb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(objective='binary:logistic',\n",
    "                            gamma=0.25, \n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=14,\n",
    "                            seed=42,\n",
    "                            reg_lambda=0,\n",
    "                            min_child_weight=1,\n",
    "                            scale_pos_weight=3,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.5)\n",
    "\n",
    "model_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "print('Accuracy of XGB classifier on training set: {:.2f}'\n",
    "       .format(model_xgb.score(X_train, y_train)))\n",
    "print('Accuracy of XGB classifier on test set: {:.2f}'\n",
    "       .format(model_xgb.score(X_test[X_train.columns], y_test)))\n",
    "\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification(model_xgb, y_pred, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_xgb,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d') #display_labels=[\"Not Taken\", \"Taken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plot_importance(model_xgb, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25c596-a7d6-4d00-ab2e-cbb38a1d02e2",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cdff7-eeb3-4b7b-82f1-e6e2a11594a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# model_DeciTr.tree_.max_depth\n",
    "# max_depth = 19\n",
    "\n",
    "for max_d in range(1,20):\n",
    "    model_DeciTr=DecisionTreeClassifier(max_depth=max_d, random_state=42)\n",
    "    model_DeciTr.fit(X_train,y_train)\n",
    "    Y_pred= model_DeciTr.predict(X_test)\n",
    "    print('The Training Accuracy for max_depth {} is:'.format(max_d), model.score(X_train,y_train))\n",
    "    print('The Validation Accuracy for max_depth {} is:'.format(max_d), model.score(X_train,y_train))\n",
    "    print('')\n",
    "# DeciTr_acc=accuracy_score(Y_test,Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3536df-55b3-49ca-8937-566aa8247ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classification(model_DeciTr, y_pred, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1835dab-f156-4cc0-806e-64a7345b94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_DeciTr,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     values_format='d') #display_labels=[\"Not Taken\", \"Taken\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394d5ac-af61-49ed-8512-7dabc22f640f",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b99b9-c1c4-4ac5-b9b3-2fcc049d13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm=SVC(kernel=\"poly\")  #alternatif lain kernel= \"linear\" or \"rbf\"\n",
    "model_svm.fit(X_train,y_train)\n",
    "Y_pred= model_svm.predict(X_test)\n",
    "eval_classification(model_svm, y_pred, X_train, y_train, X_test, y_test)\n",
    "# SVC_acc=accuracy_score(y_test,Y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078d286-4595-49c4-8d7d-890ee7ba691d",
   "metadata": {},
   "source": [
    "### KNN (K-Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f179cb0-c553-4216-9b23-eb0a7e83a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn=KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn.fit(X_train,y_train)\n",
    "Y_pred=model_knn.predict(X_test)\n",
    "eval_classification(model_knn, y_pred, X_train, y_train, X_test, y_test)\n",
    "# KNN_acc=accuracy_score(Y_test,Y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58339b-e65d-4391-8e77-617d72e6618d",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80197295-5ac2-4d82-9d43-7b24cb7c70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # JANGAN DIRUN \n",
    "# leaf_size = list(range(1,50))\n",
    "# n_neighbors = list(range(1,30))\n",
    "# p=[1,2]\n",
    "# hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "# #Create new KNN object\n",
    "# knn_2 = KNeighborsClassifier()\n",
    "# #Use GridSearch\n",
    "# clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "# #Fit the model\n",
    "# best_model = clf.fit(X_train,y_train)\n",
    "# #Print The value of best Hyperparameters\n",
    "# print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "# print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "# print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e0e92",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model_naive_bayes = GaussianNB()\n",
    "model_naive_bayes.fit(X_train, y_train)\n",
    "y_pred = model_naive_bayes.predict(X_test)\n",
    "eval_classification(model_naive_bayes, y_pred, X_train, y_train, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
